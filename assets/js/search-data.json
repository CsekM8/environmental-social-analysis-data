{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://csekm8.github.io/environmental-social-analysis/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Poverty and the well-being of NYC citizens based on environmental factors",
            "content": "from folium import plugins from folium.plugins import HeatMap from matplotlib.ticker import MaxNLocator import pandas as pd import folium import plotly.express as px import json import seaborn as sn import matplotlib.pyplot as plt import numpy as np import scipy.stats as stats import math import branca import branca.colormap as cm import warnings warnings.filterwarnings(&#39;ignore&#39;) . !ls /datasets/socialdatadump/DTU/Social/ . 1995_Street_Tree_Census.csv 2005_Street_Tree_Census.csv 2015_Street_Tree_Census_-_Tree_Data.csv 311_air_quality.csv 311_Service_Requests_for_2005.csv Air_Quality.csv community_districts.geojson new-york-city-boroughs.geojson New_York_City_Community_Health_Survey.csv NYCgov_Poverty_Measure_Data__2005_.csv . __dir__ = &#39;/datasets/socialdatadump/DTU/Social/&#39; air_quality_311 = pd.read_csv(__dir__ + &#39;311_air_quality.csv&#39;, parse_dates=True) tree_data_2005 = pd.read_csv(__dir__ + &#39;2005_Street_Tree_Census.csv&#39;) tree_data_2015 = pd.read_csv(__dir__ + &#39;2015_Street_Tree_Census_-_Tree_Data.csv&#39;) air_quaility_data = pd.read_csv(__dir__ + &#39;Air_Quality.csv&#39;, parse_dates=True) health_surveys = pd.read_csv(__dir__ + &#39;New_York_City_Community_Health_Survey.csv&#39;) . We are going to analyze New York City data both from a social and an enviromental aspect, by using the previously mentioned data on trees, air pollution, 311 complaints and poverty, to see what effects they have on one another. The observed period of time is between 2005 and 2015, let&#39;s jump right into it. First let&#39;s have a look at the number of air quality related complaints over the years. But why air quality? . Air pollution is one of the most important environmental threats to urban populations and while all people are exposed, pollutant emissions, levels of exposure, and population vulnerability vary across neighborhoods. Exposures to common air pollutants have been linked to respiratory and cardiovascular diseases, cancers, and premature deaths. . air_quality_311[&#39;Created Date&#39;] = pd.to_datetime(air_quality_311[&#39;Created Date&#39;]) _air_quality_311 = air_quality_311[air_quality_311[&#39;Created Date&#39;].dt.year &lt;= 2015] air_quality_311_by_year = _air_quality_311.groupby(_air_quality_311[&#39;Created Date&#39;].dt.year).size() plt.rcParams.update({&#39;font.size&#39;: 22}) ax = plt.figure(figsize=(20,10)).gca() ax.xaxis.set_major_locator(MaxNLocator(integer=True)) plt.bar(air_quality_311_by_year.index, air_quality_311_by_year) plt.title(&#39;No. of 311 complaints on air quailty&#39;) plt.xlabel(&#39;Year&#39;) plt.ylabel(&#39;No. of complaints&#39;) plt.show() . And for completeness&#39; sake let&#39;s have a look at it using geospatial analysis. . complaint_map = folium.Map(location=[40.730610, -73.935242], zoom_start=11, tiles=&quot;Stamen Toner&quot;) air_quality_311_for_map = air_quality_311.dropna(axis=0, subset=[&#39;Longitude&#39;,&#39;Latitude&#39;]) complaints = [[[row[&#39;Latitude&#39;], row[&#39;Longitude&#39;]] for _, row in air_quality_311_for_map[air_quality_311_for_map[&#39;Created Date&#39;].dt.year == year].iterrows()] for year in range(2005,2016)] complaint_heatmap = plugins.HeatMapWithTime(complaints, index=[x for x in range(2005, 2016)], auto_play=True, radius=5, min_opacity=0.05, max_opacity=0.9) complaint_heatmap.add_to(complaint_map) complaint_map . Make this Notebook Trusted to load map: File -&gt; Trust Notebook It would be too early to deduce any sort of conclusions from these alone, let alone say that nothing has changed over the years. First let&#39;s dive a little bit deeper into what 311 requests are: 311 is a toll-free number that allows people in the District to request assistance with city services and information. Because it is easy to use and easy to remember, 311 can help improve service delivery to residents, workers, and visitors in the nation&#39;s capital. . So anybody who asks for assistance or just wants to query information can call this number. What other aspects are contained within the data? Well most often than not the requests are for air quality issues, like odor, fumes, dust and smoke (see the plot below). So does this mean anything? . descriptors = air_quality_311.groupby(air_quality_311[&#39;Descriptor&#39;]).size().sort_values(ascending=False).head(10) ax = plt.figure(figsize=(20,5)).gca() plt.bar(descriptors.index, descriptors) plt.title(&#39;Top10 most common types of air quality issues&#39;) plt.ylabel(&#39;No. of occurrences&#39;) plt.xticks(rotation=90) plt.show() . Health surveys of New york City citizens are available since 2010. We can take a look at the correlation between the number of air quality related 311 requests and the self-reported health status. What we can see is that there is a low negative correlation between them (-0.3611), meaning that an increase in the number of requests slightly influences people&#39;s self-reported health negatively. . health_by_prevelance = health_surveys[health_surveys[&#39;Year&#39;] &lt;= 2015][health_surveys[&#39;Prevelance&#39;].str.contains(&quot;Prevalence&quot;)] for_corr_311 = air_quality_311_by_year[air_quality_311_by_year.index &gt;= 2010] # We need to reverse the list, because the order of the years are reversed health_by_prevelance.insert(1, &#39;Number of air quality issues&#39;, list(reversed(for_corr_311.values))) health_by_prevelance.corr(method=&#39;pearson&#39;)[&#39;Number of air quality issues&#39;][&#39;Self-reported Health Status (excellent/very good/good)&#39;] . -0.36113510837759755 . Well this doesn&#39;t say much. How about we introduced a new kind of dataset? Instead of looking at reports let&#39;s look at actual measurements of NYC. The air quality dataset contains information on New York City air quality surveillance data. These indicators provide a perspective across time and NYC geographies to better characterize air quality and health. . So how about different chemical concentrations in the air? Two pollutants, particulate matter and ground-level ozone, are of particular health concern, so we&#39;ll reduce the area of observations to only these two metritcs. . with open(__dir__ + &#39;community_districts.geojson&#39;) as f: districts = json.load(f) # round off, to reduce file size for i in range(0, len(districts[&quot;features&quot;])): for j in range(0,len(districts[&quot;features&quot;][i][&#39;geometry&#39;][&#39;coordinates&#39;])): try: districts[&quot;features&quot;][i][&#39;geometry&#39;][&#39;coordinates&#39;][j] = np.round(np.array(districts[&quot;features&quot;][i][&#39;geometry&#39;][&#39;coordinates&#39;][j]),3) except: print(i,j) aspects = [ &#39;Fine Particulate Matter (PM2.5)&#39;, &#39;Ozone (O3)&#39; ] all_map_data = {} air_quaility_data[&#39;Start_Date&#39;] = pd.to_datetime(air_quaility_data[&#39;Start_Date&#39;]) for aspect in aspects: data = air_quaility_data[air_quaility_data[&#39;Name&#39;] == aspect][air_quaility_data[&#39;Geo Type Name&#39;] == &#39;CD&#39;] map_data = pd.DataFrame(columns=[&#39;cd&#39;,aspect,&#39;year&#39;]) map_data[&#39;cd&#39;] = data[&#39;Geo Join ID&#39;] map_data[aspect] = data[&#39;Data Value&#39;] map_data[&#39;year&#39;] = data[&#39;Start_Date&#39;].dt.year all_map_data[aspect] = map_data for key, map_data in all_map_data.items(): max_value = map_data[key].max() fig = px.choropleth_mapbox(map_data, geojson=districts, locations=&#39;cd&#39;, color=key, color_continuous_scale=&#39;aggrnyl&#39; if key == &#39;Ozone (O3)&#39; else &#39;agsunset&#39;, range_color=(0, max_value), featureidkey=&quot;properties.BoroCD&quot;, mapbox_style=&quot;stamen-toner&quot;, opacity=0.8, center = {&quot;lat&quot;: 40.730610, &quot;lon&quot;: -73.935242}, zoom=9, animation_frame=&#39;year&#39;, title=key) fig.update_geos(fitbounds=&quot;locations&quot;,visible=False) fig.update_layout(margin={&quot;r&quot;:0,&quot;t&quot;:0,&quot;l&quot;:0,&quot;b&quot;:0},) fig.show() . CellOutputSizeError: The output can&#39;t be displayed because it exceeded 30MB in size. Please reduce volume of data sending to output. In case of problems, do not hesitate to contact Deepnote support. . What we can see is that fine particulate matter (PM2.5) is rather high in center of manhattan but relatively low in the outskirts of NYC. The opposite can be said of Ozone (O3) levels. Over the years we can see a rather drastic decrease in PM2.5 but not in O3. Contrary to what we have expected, we can see a very much visible decrease in fine particular matter over the years, especially in the center of manhattan where most of the 311 calls happen. But air pollution related 311 requests were at an all time low in 2011 and peaked again in 2015. Ozone levels did increase in 2010 and were at that level until 2013, from that point which they started drop. So what&#39;s the deal with this? Can we assume that 311 related calls are unrelated to fine particles and other air toxics? Let&#39;s look at their correlation. . start_year = 2009 end_year = 2015 column_name = &#39;311&#39; df = pd.DataFrame() for aspect in aspects: data = air_quaility_data[(air_quaility_data[&#39;Name&#39;] == aspect) &amp; (air_quaility_data[&#39;Start_Date&#39;].dt.year &lt;= end_year) &amp; ((air_quaility_data[&#39;Start_Date&#39;].dt.year &gt;= start_year))].groupby(air_quaility_data[&#39;Start_Date&#39;].dt.year)[&#39;Data Value&#39;].mean() df[aspect] = data.to_frame(name=aspect)[aspect] df[column_name] = air_quality_311[(air_quality_311[&#39;Created Date&#39;].dt.year &lt;= end_year) &amp; (air_quality_311[&#39;Created Date&#39;].dt.year &gt;= start_year)].groupby(_air_quality_311[&#39;Created Date&#39;].dt.year).size().to_frame(name = column_name)[column_name] df.rename(columns={&#39;Fine Particulate Matter (PM2.5)&#39;: &#39;PM2.5&#39;, &#39;Ozone (O3)&#39;: &#39;O3&#39;}, inplace=True) corr_airpol = df.corr(method=&#39;pearson&#39;) sn.heatmap(corr_airpol, annot=True, cmap=&#39;YlGn&#39;) plt.show() . So not unrelated, but there is a mild and moderate negative correlation between air quality and the number of 311 calls. Complitely the opposite of what one would expect. Or is it? It wouldn&#39;t make sense to question it were it not for the case that these are micro particles and cannot be seen by the naked eye. Humans are kind of perceptive in a sense that they are only aware of things negatively impacting them if they can actually feel the impact. A person would only report something via the 311 number if they noticed it. Let it be smoke, dust etc etc. Fine particles and Ozone cannot be detected without the capability of measuring them, but they are sure to leave their mark on one&#39;s health. . So us, humans, are mostly unaware of this impact, so naturally on the individual&#39;s level the problem is rather difficult to solve. Large-scale solutions and raising awareness of these issues are of great importance. . New York City’s air quality has improved recently, as the City and State have worked to lower emissions from regional and local sources. Despite this progress, air pollution remains a leading environmental health threat to all New Yorkers. Those most at risk include older adults, children and people with preexisting health conditions. . So what can we do as a society? . . Well, trees, besides indirectly affecting temperature by being very good at shading surfaces, reducing temperatures and thus decreasing risk of harmful pollutants like ground level ozone that commonly spike on hot days in urban areas, are rather potent at removing particulate matter from the air. So more trees equals less particles, right? Well let&#39;s see that! . Street tree data from the TreesCount! 2005 and 2015 Street Tree Census, is conducted by volunteers and staff organized by NYC Parks &amp; Recreation and partner organizations. Tree data collected includes tree species, diameter and perception of health. Accompanying blockface data is available indicating status of data collection and data release citywide. . We can check how many more trees there are in certain community districts . tree_map = folium.Map(location=[40.730610, -73.935242], zoom_start=11, tiles=&quot;Stamen Toner&quot;) datasets = {&#39;cb_num&#39;: tree_data_2005, &#39;community board&#39;: tree_data_2015} for key, dataset in datasets.items(): data = dataset.groupby(dataset[key]).size().to_frame(name=&#39;number&#39;).reset_index() max_value = data[&#39;number&#39;].max() fig = px.choropleth_mapbox(data, geojson=districts, locations=key, color=&#39;number&#39;, color_continuous_scale=&#39;greens&#39;, range_color=(0, max_value), featureidkey=&quot;properties.BoroCD&quot;, mapbox_style=&quot;stamen-toner&quot;, opacity=0.8, center = {&quot;lat&quot;: 40.730610, &quot;lon&quot;: -73.935242}, zoom=9, title=&quot;Trees in 2005&quot; if key == &#39;cb_num&#39; else &quot;Trees in 2015&quot;) fig.update_geos(fitbounds=&quot;locations&quot;,visible=False) fig.update_layout(margin={&quot;r&quot;:0,&quot;t&quot;:0,&quot;l&quot;:0,&quot;b&quot;:0},) fig.show() . . . . . There are two things we can talk about here: there has been an increase in the amount of trees there are all around NYC and that the outer skirts of the city are the dominant ones regarding this number. What is to be expected though, is that if we were to invert the colors of the map it would resemble tha PM2.5 map shown above. Let&#39;s check if they actually correlate. . df = tree_data_2015.groupby(tree_data_2015[&#39;community board&#39;]).size().to_frame(name=&#39;Trees&#39;).reset_index() _data = air_quaility_data[air_quaility_data[&#39;Name&#39;] == &#39;Fine Particulate Matter (PM2.5)&#39;][air_quaility_data[&#39;Geo Type Name&#39;] == &#39;CD&#39;][air_quaility_data[&#39;Start_Date&#39;].dt.year == 2015] air_quaility_data_by_cd = _data.groupby(_data[&#39;Geo Join ID&#39;])[&#39;Data Value&#39;].mean() df[&#39;PM2.5&#39;] = air_quaility_data_by_cd.to_frame(name=&#39;pm2.5&#39;).reset_index()[&#39;pm2.5&#39;] df.rename(columns={&#39;community board&#39;: &#39;District&#39;}, inplace=True) fig, ax = plt.subplots(figsize=(20,10)) sn.heatmap(df.corr(method=&#39;pearson&#39;), annot=True, cmap=&#39;YlGn_r&#39;,ax=ax) plt.show() . So there we have . &lt;/img&gt; Created in Deepnote .",
            "url": "https://csekm8.github.io/environmental-social-analysis/2020/01/28/Environmental-Social-Data-Analysis.html",
            "relUrl": "/2020/01/28/Environmental-Social-Data-Analysis.html",
            "date": " • Jan 28, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://csekm8.github.io/environmental-social-analysis/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://csekm8.github.io/environmental-social-analysis/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}